configfile: "config.yaml"

from itertools import chain
from functools import partial
import os.path

from scripts.common import detect_reads

#Config parameters
LOCAL_DIR = config.get("LOCAL_DIR", "")
default_values = {
    "bin":         os.path.join(LOCAL_DIR, "build/release/bin"),
    "scripts":     os.path.join(LOCAL_DIR, "src/projects/mts/scripts"),
    "threads":     16,
    "assembly":    {"assembler": "spades", "dir": os.path.join(LOCAL_DIR, "bin"), "k": 55, "groups": []},
    "profile":     {"profiler": "mts", "k": 21, "split": 10000},
    "binning":     {"binner": "canopy", "min_length": 2000, "min_nonzeroes": 3},
    "propagation": {"enabled": True},
    "reassembly":  {"enabled": True}
}

# Taken from http://stackoverflow.com/questions/36831998/how-to-fill-default-parameters-in-yaml-file-using-python
def setdefault_recursively(tgt, default = default_values):
    for k in default:
        if isinstance(default[k], dict): # if the current item is a dict,
            # expand it recursively
            setdefault_recursively(tgt.setdefault(k, {}), default[k])
        else:
            # ... otherwise simply set a default value if it's not set before
            tgt.setdefault(k, default[k])

setdefault_recursively(config)

config["reassembly"].setdefault("dir", config["assembly"]["dir"])

#TODO: check if modern Snakemake allows dictionaries in string splicing
IN = config["data"]
ASSEMBLER = config["assembly"]["assembler"]
ASSEMBLER_DIR = config["assembly"]["dir"]
REASSEMBLER_DIR = config["reassembly"]["dir"]
BIN = config["bin"]
SCRIPTS = config["scripts"]
SOFT = config["soft"]
K = config["assembly"]["k"]
SMALL_K = config["profile"]["k"]
PROFILER = config["profile"]["profiler"]
SPLIT_LENGTH = config["profile"]["split"]
MIN_CONTIG_LENGTH = config["binning"]["min_length"]
MIN_NONZEROES = config["binning"]["min_nonzeroes"]
THREADS = config["threads"]
BINNER = config["binning"]["binner"]

#Autodetect samples and their reads
SAMPLE_DIRS = set(glob_wildcards(os.path.join(IN, "{sample,sample\d+}"))[0])
SAMPLE_COUNT = len(SAMPLE_DIRS)
SAMPLES = list()
for i in range(1, SAMPLE_COUNT + 1):
    sample_name = "sample" + str(i)
    if sample_name not in SAMPLE_DIRS:
        raise WorkflowError("Samples must be consecutive; missing " + sample_name)
    SAMPLES.append(sample_name)

SAMPLE_READS = dict(map(lambda sample: (sample, detect_reads(os.path.join(IN, sample))), SAMPLES))

NAME_TEMPLATE = "(\w+\.?)?\d+"

#Group samples
GROUP_SAMPLES = config["assembly"]["groups"]
USED_SAMPLES = set(chain(*GROUP_SAMPLES))
#TODO: double-check
#Replace the wildcard group with unused samples
if GROUP_SAMPLES and GROUP_SAMPLES[-1] == "*":
    GROUP_SAMPLES[-1] = [sample for sample in SAMPLES if sample not in USED_SAMPLES]
#Otherwise, add a single-sample group from the rest of the samples
else:
    for sample in SAMPLES:
        if sample not in USED_SAMPLES:
            GROUP_SAMPLES.append([sample])

GROUPS = dict()
group_id = 1
for group in GROUP_SAMPLES:
    if len(group) == 1:
        key = group[0]
    else:
        key = "group" + str(group_id)
        #SAMPLE_READS[key] = ["reads/{}/{}.fastq".format(key, dir) for dir in ["left", "right"]]
        SAMPLE_READS[key] = ([SAMPLE_READS[s][0] for s in group], [SAMPLE_READS[s][1] for s in group])
        group_id += 1
    GROUPS[key] = group

#Helpers for locating input files
def sample_reads(dir, wildcards):
    res = SAMPLE_READS[wildcards.sample][dir]
    if res is str:
        return [res]
    else:
        return res

left_reads  = partial(sample_reads, 0)
right_reads = partial(sample_reads, 1)

rule combine_splits:
    input:   expand("{{dir}}/{sample}.fasta", sample=GROUPS)
    output:  "{dir}/all.fasta"
    message: "Combine all contigs from {wildcards.dir}"
    shell:   "{SCRIPTS}/combine_contigs.py -r {input} > {output}"
