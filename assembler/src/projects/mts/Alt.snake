include: "Common.snake"

import functools
import itertools

from Bio import SeqIO

from scripts.parse_output import ConcoctParser

ASSEMBLER = config["assembly"]["assembler"]

LEFT_READS = [reads[0] for reads in SAMPLE_READS.values()]
RIGHT_READS = [reads[1] for reads in SAMPLE_READS.values()]

def sample_reads(dir, wildcards):
    return SAMPLE_READS[wildcards.sample][dir]

left_reads  = functools.partial(sample_reads, 0)
right_reads = functools.partial(sample_reads, 1)

rule all:
    input:   "binning/{}/binning.done".format(BINNER)

# Assemble with MegaHIT
rule megahit:
    input:   LEFT_READS, RIGHT_READS
    output:  "assembly/megahit/samples.fasta"
    params:  dir="assembly/megahit", left=",".join(LEFT_READS), right=",".join(RIGHT_READS)
    threads: THREADS
    log:     "assembly/megahit.log"
    message: "Assembling all samples with MegaHIT"
    shell:   "rm -rf {params.dir} &&"
             " {SOFT}/megahit/megahit -1 {params.left} -2 {params.right} -t {threads} -o {params.dir} >{log} 2>&1 &&"
             " cp {params.dir}/final.contigs.fa {output}"

# Assemble with SPAdes
rule spades:
    input:   LEFT_READS, RIGHT_READS
    output:  "assembly/spades/samples.fasta"
    params:  left=" ".join(["-1 {}".format(SAMPLE_READS[s][0]) for s in SAMPLES]),
             right=" ".join(["-2 {}".format(SAMPLE_READS[s][1]) for s in SAMPLES]),
             dir="assembly/spades"
    threads: THREADS
    log:     "assembly/spades.log"
    message: "Assembling all samples with metaSPAdes"
    shell:   "{SPADES}/spades.py --meta -m 400 -t {threads} {params.left} {params.right}"
             " -o {params.dir} >{log} 2>&1 && "
             "cp {params.dir}/scaffolds.fasta {output}"

rule coassemble:
    input:   "assembly/{}/samples.fasta".format(ASSEMBLER)
    output:  "assembly/samples.fasta"
    shell:   "cd assembly && ln -fs {ASSEMBLER}/samples.fasta samples.fasta"

# Common stuff
rule cut_fragments:
    input:   "assembly/samples.fasta"
    output:  "assembly/samples_frags.fasta"
    params:  split=10000
    shell:   "python2 {SOFT}/CONCOCT/scripts/cut_up_fasta.py -c {params.split} -o 0 -m {input} > {output}"

rule bowtie_index:
    input:   "assembly/{frags}.fasta"
    output:  "align/index_{frags}.done"
    log:     "align/bowtie_{frags}.log"
    message: "Building bowtie index"
    shell:   "bowtie2-build {input} align/index_{wildcards.frags} >{log} 2>&1 && touch {output}"

#---- Generating profiles/depths -----------------------------------------------

# MetaBAT way

rule align:
    input:   left=left_reads, right=right_reads,
             index="align/index_{frags}.done"
    output:  "align/{frags}/{sample}.bam"
    threads: THREADS
    message: "Aligning {wildcards.sample} with bowtie"
    shell:   "bowtie2 -x align/index_{wildcards.frags} -p {threads} -1 {input.left} -2 {input.right} |"
             " samtools view -bS - > {output}"

rule depth:
    input:   expand("align/{{frags}}/{sample}.bam", sample=SAMPLES)
    output:  "profile/{frags}/depth_metabat.txt"
    message: "Calculating contig depths"
    shell:   "{SOFT}/metabat/jgi_summarize_bam_contig_depths --outputDepth {output} {input}"

rule concoct_depth:
    input:   "profile/samples_frags/depth_metabat.txt"
    output:  "profile/depth_concoct.txt"
    message: "Converting depth file into CONCOCT format"
    shell:   "awk 'NR > 1 {{for(x=1;x<=NF;x++) if(x == 1 || (x >= 4 && x % 2 == 0)) printf \"%s\", $x (x == NF || x == (NF-1) ? \"\\n\":\"\\t\")}}' {input} > {output}"

rule maxbin_depth:
    input:   "profile/depth_concoct.txt"
    output:  "profile/depth_maxbin_list.txt"
    params:  prefix="profile/depth_maxbin"
    message: "Preparing input for Maxbin"
    shell:   "{SCRIPTS}/make_maxbinin.py -p {input} -o {params.prefix}"

#---- Binning with CONCOCT -----------------------------------------------------

rule concoct:
    input:   contigs="assembly/samples_frags.fasta", profiles="profile/depth_concoct.txt"
    output:  "binning/concoct/tables/clustering_gt{}.csv".format(MIN_CONTIG_LENGTH)
    params:  max_clusters=40, out="binning/concoct/tables"
    threads: THREADS
    log:     "binning/concoct.log"
    message: "Running CONCOCT clustering"
    shell:   "mkdir -p {params} && "
             "set +u; source activate concoct_env; set -u && "
             "concoct -c {params.max_clusters} --composition_file {input.contigs}"
             " --coverage_file {input.profiles} --length_threshold {MIN_CONTIG_LENGTH}"
             " -b {params.out} > {log}"

rule concoct_post:
    input:   contigs="assembly/samples_frags.fasta",
             binning="binning/concoct/tables/clustering_gt{}.csv".format(MIN_CONTIG_LENGTH)
    output:  touch("binning/concoct/binning.done")
    params:  out="binning/concoct"
    message: "Extracting CONCOCT bins"
    run:
        shell("rm -f {}/cluster*.fa".format(params.out))
        parser = ConcoctParser()
        parser.parse_file(input.binning)
        ann = parser.samples_annotation["all"]
        for seq in SeqIO.parse(input.contigs, "fasta"):
            seq_id = ann.get(seq.id)
            if not seq_id:
                continue
            with open("{}/cluster.{}.fa".format(params.out, seq_id[0]), "a") as output:
                SeqIO.write(seq, output, "fasta")

#---- Binning with MetaBAT -----------------------------------------------------

rule metabat:
    input:   contigs="assembly/samples.fasta", profiles="profile/samples/depth_metabat.txt"
    output:  flag=touch("binning/metabat/binning.done"),
             ann=("annotation/metabat/samples.ann")
             #dynamic("binning/metabat/{cluster}.fa")
    threads: THREADS
    params:  out="binning/metabat/cluster"
    log:     "binning/metabat.log"
    message: "Running MetaBAT clustering"
    shell:   "{SOFT}/metabat/metabat -t {threads} -m {MIN_CONTIG_LENGTH} "
             " --minContigByCorr {MIN_CONTIG_LENGTH} --saveCls"
             " -i {input.contigs} -a {input.profiles}"
             " -o {params.out} > {log} &&"
             "sed 's/\t/ : /g' {params} > {output.ann}"
        # with open(output.ann, "w") as out_file:
        #     with open(params.out, "r") as in_file:
        #         for line in in_file:

        #for cag in glob_wildcards("binning/metabat/{CAG}.fa")[0]:
        #    os.link("binning/metabat/{}.fa".format(cag), "reassembly/CAG{}.fasta".format(cag))

rule binning:
    input:   "binning/{}/binning.done".format(BINNER)
    message: "Finished the pipeline"

#---- Binning with MaxBin2 --------------------------------------------------------

rule maxbin:
    input:   contigs="assembly/samples_frags.fasta", profiles_list="profile/depth_maxbin_list.txt"
    output:  flag=touch("binning/maxbin/binning.done"),
             ann=("annotation/metabat/samples.ann") 
    threads: THREADS
    params:  out="binning/maxbin/cluster", csv="binning/maxbin/clustering.csv"
    log:     "binning/maxbin.log"
    message: "Running MaxBin clustering"
    shell:   "perl {SOFT}/MaxBin/run_MaxBin.pl -thread {threads} -min_contig_length {MIN_CONTIG_LENGTH} -prob_threshold 0.3"
             " -contig {input.contigs} -abund_list {input.profiles_list}"
             " -out {params.out} > {log}"
             "&& {SCRIPTS}/make_maxbincsv.py -o {params.csv} {params.out}"
             "&& sed 's/,/ : /g' {params.csv} > {output.ann}"


#---- Binning with DBScan ------------------------------------------------------

# TODO

#---- Binning with Canopy ------------------------------------------------------

# TODO

#---- Optional propagator for SPAdes assembly ----------------------------------

#Path to saves of necessary assembly stage
SAVES = "K{0}/saves/01_before_repeat_resolution/graph_pack".format(K)

rule prop_binning:
    input:   contigs="assembly/spades/samples.fasta", ann="annotation/{binner}/samples.ann",
    output:  "annotation/{binner}/samples_prop_edges.ann"
    params:  saves=os.path.join("assembly/spades/", SAVES),
             splits="assembly/samples_frags.fasta", out="assembly/samples_edges",
             left=" ".join(LEFT_READS), right=" ".join(RIGHT_READS)
    log:     "annotation/{binner}/propagator.log"
    message: "Propagating annotation & binning reads"
    shell:
          "{BIN}/prop_binning -k {K} -s {params.saves} -c {input.contigs}"
          " -n samples -l {params.left} -r {params.right}"
          " -a {input.ann} -f {params.splits} -o binning -d {params.out} >{log} 2>&1"

rule propagate:
    input:   "annotation/{}/samples_prop_edges.ann".format(BINNER)
