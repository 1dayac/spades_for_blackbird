include: "Common.snake"

import os
import os.path

import pandas
from pandas import DataFrame

from scripts.common import gather_refs

#Additional config parameters
try:
    QUAST_DIR = config["QUAST"]
    QUAST = os.path.join(QUAST_DIR, "quast.py")
    METAQUAST = os.path.join(QUAST_DIR, "metaquast.py")
except KeyError:
    QUAST = "quast"
    METAQUAST = "metaquast"

#Autodetect bins
if config["reassembly"]["enabled"]:
    BINS, = glob_wildcards("binning/{{bin,{}}}.info".format(NAME_TEMPLATE))
else:
    BINS, = glob_wildcards("binning/bins/{{bin,{}}}.fasta".format(NAME_TEMPLATE))
if not BINS:
    raise WorkflowError("No bins detected!")
BINS.sort()

#Additional config parameters
try:
    QUAST_DIR = config["stats"]["quast"]
    QUAST = os.path.join(QUAST_DIR, "quast.py")
    METAQUAST = os.path.join(QUAST_DIR, "metaquast.py")
except KeyError:
    QUAST = "quast"
    METAQUAST = "metaquast"

#Detect references
REFS = dict(gather_refs(config["stats"].get("refs", [])))
REFS_STR = ",".join(path for path in REFS.values())

def ref_path(wildcards):
    return REFS[wildcards.ref]

onstart:
    print("Detected", SAMPLE_COUNT, "samples in", IN)
    if BINS:
        print("Detected good (abundant) bins:", " ".join(BINS))
    if REFS:
        print("Detected references:", " ".join(REFS))

enabled_stats = []
if config["stats"].get("refs"):
    enabled_stats.append["stats/summary/gf_binning.tsv"]
    if config["propagation"]["enabled"]:
        enabled_stats.append("stats/summary/gf_propagation.tsv")
    if config["reassembly"]["enabled"]:
        enabled_stats.append("stats/summary/reassembly_summary.tsv")
if config["stats"].get("checkm", False):
    enabled_stats.append("stats/summary/checkm_reassembly.tsv")

rule all_stats:
    input:   enabled_stats
    message: "Gathered stats: {input}"

#---- Contigs of interest ------------------------------------------------------
# rule filter_ref_alignments:
#     input:   "stats/summary/gf_{stage}.tsv"
#     output:  "stats/q_{stage}/runs_per_reference/{ref}/{fragments}.info"
#     params:  "stats/q_{stage}/runs_per_reference/{ref}/contigs_reports/nucmer_output/{fragments}.coords.filtered"
#     message: "Filtering alignments of {wildcards.fragments} from {wildcards.stage} onto {wildcards.ref}"
#     shell:   "if [ -f {params} ] ; then {SCRIPTS}/filter_nucmer.py {params} {output} {MIN_CONTIG_LENGTH} 70 ; else touch {output} ; fi"
#
# def alignment_input(wildcards):
#     template = "stats/q_{}/runs_per_reference/{{ref}}/{{fragments}}.info".format(wildcards.stage)
#     return expand(template, ref = wildcards.ref, fragments=input_dict[wildcards.stage].fragments)
#
# rule combine_alignment_info:
#     input:   alignment_input
#     output:  "stats/q_{stage}/g_{ref}.info"
#     message: "Combining good contigs of {wildcards.stage} for {wildcards.ref}"
#     shell:   "rm -rf {output}; for f in {input}; do name=$(basename $f .info); cat $f | sed 's/^/'$name'-/g' >> {output} ; done"
#
# rule combine_refs_info:
#     input:   expand("stats/q_{{stage}}/g_{ref}.info", ref=list(REFS.keys()))
#     output:  "stats/q_{stage}/total.info"
#     message: "Combining good contigs of {wildcards.stage} for all references"
#     run:
#         shell("rm -f {output}")
#         for ref in REFS.keys():
#             shell("awk '{{print $0 \"\t{ref}\"}}' stats/q_{wildcards.stage}/g_{ref}.info >> {output}")

#---- Summary table ------------------------------------------------------------
rule gather_stats:
    input:   "stats/summary/gf_{stage}.tsv"#,
             #"stats/q_{stage}/total.info"
    output:  "stats/summary/{stage}_summary.tsv"
    params:  "--problematic", "--heatmap", "stats/q_{stage}", "stats/summary/{stage}"
    message: "Gathering {wildcards.stage} stats"
    shell:   "{SCRIPTS}/gather_stats.py {params}"

#===============================================================================
#---- Statistics section -------------------------------------------------------
#===============================================================================

#---- Genome fraction ----------------------------------------------------------
rule genome_fraction:
    input:   expand("{{stage}}/bins/{bin}.fasta", bin=BINS) #stats_input
    output:  "stats/summary/gf_{stage}.tsv"
    params:  out="stats/q_{stage}"
    log:     "stats/q_{stage}/.log"
    threads: THREADS
    message: "Aligning all of {wildcards.stage} on all references"
    shell:   "{METAQUAST} -t {threads} -R {REFS_STR} {input} -o {params.out} >/dev/null 2>&1 && "
             "cp '{params.out}/summary/TSV/Genome_fraction_(%).tsv' {output}"

#---- GF per bin per reference -------------------------------------------------
CONTIGS_INPUT_DIR = {"binning": "assembly/splits/", "propagation": "propagation/edges/"}

#Redistribute sample pieces to corresponding bins
rule filter_bin:
    input:   contigs=lambda w: "{}/all.fasta".format(CONTIGS_INPUT_DIR[w.stage]),
             ann="{stage}/annotation/all.ann"
    output:  "{stage,(binning|propagation)}/bins/{bin,\w*\d+}.fasta"
    message: "Filtering contigs from {wildcards.bin} for all of {wildcards.stage}"
    shell:   "{SCRIPTS}/filter_bin.py {input.contigs} {input.ann} {wildcards.bin} >{output}"

#---- Propagator statistics ----------------------------------------------------
# rule prop_stats:
#     input:   prelim="binning/annotation/{sample}.ann", prop="propagation/annotation/{sample}.ann",
#              contigs="assembly/{sample}.fasta", edges="assembly/edges/{sample}.fasta",
#              ref=REFS.values() #, bins="{sample}/{ref}.bin"
#     output:  "stats/prop_{bin}/{sample}.tsv"
#     log:     "stats/prop_{bin}/{sample}.log"
#     message: "Calculating propagation statistics for {wildcards.sample}"
#     shell:   "{BIN}/stats -k {K} -s {wildcards.sample}/assembly/{SAVES} -r {input.ref}"
#              " -c {input.contigs} -a {input.prelim} -e {input.edges} -p {input.prop}"
#              " -b {wildcards.bin} -o {output} >{log}"

# Run this
# rule prop_stats_all:
#     input:   expand("stats/prop_{cag}/{sample}.tsv", sample=GROUPS, cag=BINS)
#     message: "Calculated propagation statistics"

#===============================================================================
#---- Reference-free stats and metrics -----------------------------------------
#===============================================================================

#---- CheckM stats -------------------------------------------------------------
rule checkm:
    output:  qa="stats/checkm_{stage}/qa.tsv", tree_qa="stats/checkm_{stage}/tree_qa.tsv"
    params:  dir="{stage}/bins", out="stats/checkm_{stage}",
    threads: THREADS
    log:     "stats/checkm_{stage}.log"
    message: "Running CheckM for results of {wildcards.stage}"
    run:
        # for file in os.listdir(params.dir):
        #     ext = os.path.splitext(file)
        #     if ext in FASTA_EXTS:
        #         break
        ext = ".fasta"
        shell("set +u; source activate concoct_env; set -u \n"
             "checkm tree -x {ext} {params.dir} {params.out} >{log} \n"
             "checkm tree_qa -o 2 --tab_table -f {output.tree_qa} {params.out} >>{log}\n"
             "checkm lineage_set {params.out} {params.out}/lineage.ms >>{log}\n"
             "checkm analyze -x fasta {params.out}/lineage.ms {params.dir} {params.out} >>{log}\n"
             "checkm qa -o 2 --tab_table -f {output.qa} {params.out}/lineage.ms {params.out} >>{log}")

rule parse_checkm:
    input:   qa=rules.checkm.output.qa, tree_qa=rules.checkm.output.tree_qa
    output:  "stats/summary/checkm_{stage}.tsv"
    run:
        table = pandas.read_table(input.qa, dtype="str")
        tree_table = pandas.read_table(input.tree_qa, dtype="str", na_filter=False)
        all_table = pandas.merge(table, tree_table, on="Bin Id")
        res_table = all_table[["Bin Id", "Taxonomy (contained)", "Taxonomy (sister lineage)", "Genome size (Mbp)", "Completeness", "Contamination"]].copy()
        def extract_taxon(taxonomy):
            return str(taxonomy).split(";")[-1]
        for column in ["Taxonomy (contained)", "Taxonomy (sister lineage)"]:
            res_table[column] = res_table[column].apply(extract_taxon)
        res_table.to_csv(output[0], index=False, sep="\t")

#---- PCA ----------------------------------------------------------------------
# FRAGMENT_NAMES_BY_STAGE = {"reassembly": CAG_EDGES,
#                            "assembly": list(GROUPS.keys())}
#
# def fragments_info_by_stage(wildcards):
#     fragments=FRAGMENT_NAMES_BY_STAGE[wildcards.stage]
#     return expand("stats/q_{stage}/runs_per_reference/{ref}/{fs}.info", stage=wildcards.stage, ref=wildcards.ref, fs=fragments)
#
# rule pca:
#     input:   "binning/canopy/profiles.in", "binning/canopy/binning.out", "stats/q_{stage}/total.info"
#     output:  "stats/summary/pca_{stage}.png"
#     message: "Drawing PCA visualisation for {wildcards.stage}"
#     shell:   "Rscript {SCRIPTS}/pca.R {input} {output}"
#
# # Run this
# rule pca_all:
#     input:   expand("stats/summary/pca_{stage}.png", stage=FRAGMENT_NAMES_BY_STAGE.keys())
#     message: "Drew all PCAs"


#---- TSNE ----------------------------------------------------------------------

# rule tsne:
#     input:   profile="binning/canopy/profiles.in", binning="binning/canopy/binning.out"
#     output:  "stats/summary/tsne_{stage}"
#     message: "Drawing BH-TSNE visualisation for {wildcards.stage}"
#     shell:   "python2 {SCRIPTS}/run_tsne.py {input.profile} {input.binning} {output} -l metaSPAdes --percent 1.0 --iteration 2000 --perplexity 50"
#
# # Run this
# rule tsne_all:
#     input:   expand("stats/summary/tsne_{stage}.pdf", stage=FRAGMENT_NAMES_BY_STAGE.keys())
#     message: "Drew all TSNEs"
