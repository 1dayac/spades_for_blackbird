include: "Common.snake"

import os
import os.path

import pandas
from pandas import DataFrame

from scripts.common import gather_refs

#Additional config parameters
try:
    QUAST_DIR = config["QUAST"]
    QUAST = os.path.join(QUAST_DIR, "quast.py")
    METAQUAST = os.path.join(QUAST_DIR, "metaquast.py")
except KeyError:
    QUAST = "quast"
    METAQUAST = "metaquast"

#Autodetect bins
if config["reassembly"]["enabled"]:
    BINS, = glob_wildcards("binning/{{bin,{}}}.info".format(NAME_TEMPLATE))
else:
    BINS, = glob_wildcards("binning/bins/{{bin,{}}}.fasta".format(NAME_TEMPLATE))
if not BINS:
    raise WorkflowError("No bins detected!")
BINS.sort()

#Additional config parameters
try:
    QUAST_DIR = config["stats"]["quast"]
    QUAST = os.path.join(QUAST_DIR, "quast.py")
    METAQUAST = os.path.join(QUAST_DIR, "metaquast.py")
except KeyError:
    QUAST = "quast"
    METAQUAST = "metaquast"

#Detect references
REFS = dict(gather_refs(config["stats"].get("refs", [])))
REFS_STR = ",".join(path for path in sorted(REFS.values()))

def ref_path(wildcards):
    return REFS[wildcards.ref]

onstart:
    print("Detected", SAMPLE_COUNT, "samples in", IN)
    if BINS:
        print("Detected good (abundant) bins:", " ".join(BINS))
    if REFS:
        print("Detected references:", " ".join(REFS))

enabled_stats = []
stats_targets = {"checkm": "checkm_{}.tsv",
                 "pca":    "pca_{}.png",
                 "tsne":   "tsne_{}.png",
                 "f1":     "f1_{}.txt"}
if config["stats"].get("refs"):
    if config["profile"].get("profile") == "mts":
        enabled_stats.append("stats/summary/refs_profiles.tsv")
    stats_targets["gf"] = "gf_{}.tsv"
    stats_targets["summary"] = "{}_summary.tsv"
for stage in ["binning", "propagation", "reassembly"]:
    stage_stats = config["stats"].get(stage, [])
    if stage_stats == "all":
        stats = stats_targets.keys()
    else:
        stats = stage_stats + config["stats"].get("all", [])
    enabled_stats.extend(os.path.join("stats/summary", stats_targets[st].format(stage)) for st in stats)

rule all_stats:
    input:   enabled_stats
    message: "Gathered stats: {input}"

#---- Contigs of interest ------------------------------------------------------
# rule filter_ref_alignments:
#     input:   "stats/summary/gf_{stage}.tsv"
#     output:  "stats/q_{stage}/runs_per_reference/{ref}/{fragments}.info"
#     params:  "stats/q_{stage}/runs_per_reference/{ref}/contigs_reports/nucmer_output/{fragments}.coords.filtered"
#     message: "Filtering alignments of {wildcards.fragments} from {wildcards.stage} onto {wildcards.ref}"
#     shell:   "if [ -f {params} ] ; then {SCRIPTS}/filter_nucmer.py {params} {output} {MIN_CONTIG_LENGTH} 70 ; else touch {output} ; fi"
#
# def alignment_input(wildcards):
#     template = "stats/q_{}/runs_per_reference/{{ref}}/{{fragments}}.info".format(wildcards.stage)
#     return expand(template, ref = wildcards.ref, fragments=input_dict[wildcards.stage].fragments)
#
# rule combine_alignment_info:
#     input:   alignment_input
#     output:  "stats/q_{stage}/g_{ref}.info"
#     message: "Combining good contigs of {wildcards.stage} for {wildcards.ref}"
#     shell:   "rm -rf {output}; for f in {input}; do name=$(basename $f .info); cat $f | sed 's/^/'$name'-/g' >> {output} ; done"
#
# rule combine_refs_info:
#     input:   expand("stats/q_{{stage}}/g_{ref}.info", ref=list(REFS.keys()))
#     output:  "stats/q_{stage}/total.info"
#     message: "Combining good contigs of {wildcards.stage} for all references"
#     run:
#         shell("rm -f {output}")
#         for ref in REFS.keys():
#             shell("awk '{{print $0 \"\t{ref}\"}}' stats/q_{wildcards.stage}/g_{ref}.info >> {output}")

#---- Summary table ------------------------------------------------------------
rule gather_stats:
    input:   "stats/summary/gf_{stage}.tsv"
    output:  "stats/summary/{stage}_summary.tsv"
    params:  "--problematic", "--heatmap", "stats/q_{stage}", "stats/summary/{stage}"
    message: "Gathering {wildcards.stage} stats"
    shell:   "{SCRIPTS}/gather_stats.py {params}"

#===============================================================================
#---- Statistics section -------------------------------------------------------
#===============================================================================

#---- Reference profiles
rule combine_refs:
    input:   list(REFS.values())
    output:  "stats/refs.fasta"
    message: "Combining all references in a single file"
    shell:   "cat {input} > {output}"

rule ref_profiles:
    input:   "stats/refs.fasta"
    output:  "stats/summary/refs_profiles.tsv"
    log:     "stats/refs_profiles.log"
    message: "Calculating etalon profiles of references"
    shell:   "{BIN}/contig_abundance_counter -k {PROFILE_K} -w tmp -c {input}"
             " -n {SAMPLE_COUNT} -m profile/mts/kmers -o {output} >{log} 2>&1"

#---- Genome fraction ----------------------------------------------------------
rule genome_fraction:
    input:   expand("{{stage}}/bins/{bin}.fasta", bin=BINS) #stats_input
    output:  "stats/summary/gf_{stage}.tsv"
    params:  out="stats/q_{stage}"
    log:     "stats/q_{stage}/.log"
    threads: THREADS
    message: "Aligning all of {wildcards.stage} on all references"
    shell:   "{METAQUAST} -t {threads} -R {REFS_STR} {input} -o {params.out} >/dev/null 2>&1 && "
             "cp '{params.out}/summary/TSV/Genome_fraction_(%).tsv' {output}"

#---- GF per bin per reference -------------------------------------------------
CONTIGS_INPUT_DIR = {"binning": "assembly/splits", "propagation": "propagation/edges"}

rule combine_splits:
    input:   expand("propagation/edges/{group}.fasta", assembler=ASSEMBLER, group=GROUPS)
    output:  "propagation/edges/all.fasta"
    message: "Combine all propagated edges"
    shell:   "{SCRIPTS}/combine_contigs.py {input} > {output}"

#Redistribute sample pieces to corresponding bins
rule filter_bin:
    input:   contigs=lambda w: "{}/all.fasta".format(CONTIGS_INPUT_DIR[w.stage]),
             ann="{stage}/annotation/all.ann"
    output:  "{stage,(binning|propagation)}/bins/{bin,\w*\d+}.fasta"
    message: "Filtering contigs from {wildcards.bin} for all of {wildcards.stage}"
    shell:   "{SCRIPTS}/filter_bin.py {input.contigs} {input.ann} {wildcards.bin} >{output}"

#---- Propagator statistics ----------------------------------------------------
# rule prop_stats:
#     input:   prelim="binning/annotation/{sample}.ann", prop="propagation/annotation/{sample}.ann",
#              contigs="assembly/{sample}.fasta", edges="assembly/edges/{sample}.fasta",
#              ref=REFS.values() #, bins="{sample}/{ref}.bin"
#     output:  "stats/prop_{bin}/{sample}.tsv"
#     log:     "stats/prop_{bin}/{sample}.log"
#     message: "Calculating propagation statistics for {wildcards.sample}"
#     shell:   "{BIN}/stats -k {K} -s {wildcards.sample}/assembly/{SAVES} -r {input.ref}"
#              " -c {input.contigs} -a {input.prelim} -e {input.edges} -p {input.prop}"
#              " -b {wildcards.bin} -o {output} >{log}"

# Run this
# rule prop_stats_all:
#     input:   expand("stats/prop_{cag}/{sample}.tsv", sample=GROUPS, cag=BINS)
#     message: "Calculated propagation statistics"

#===============================================================================
#---- Reference-free stats and metrics -----------------------------------------
#===============================================================================

#---- CheckM stats -------------------------------------------------------------
rule checkm:
    output:  qa="stats/checkm_{stage}/qa.tsv", tree_qa="stats/checkm_{stage}/tree_qa.tsv"
    params:  dir="{stage}/bins", out="stats/checkm_{stage}",
    threads: THREADS
    log:     "stats/checkm_{stage}.log"
    message: "Running CheckM for results of {wildcards.stage}"
    run:
        # for file in os.listdir(params.dir):
        #     ext = os.path.splitext(file)
        #     if ext in FASTA_EXTS:
        #         break
        ext = ".fasta"
        shell("set +u; source activate py27; set -u \n"
             "checkm tree -t {THREADS} --pplacer_threads {THREADS} -x {ext} {params.dir} {params.out} >{log} 2>&1\n"
             "checkm tree_qa -o 2 --tab_table -f {output.tree_qa} {params.out} >>{log} 2>&1\n"
             "checkm lineage_set {params.out} {params.out}/lineage.ms >>{log} 2>&1\n"
             "checkm analyze -t {THREADS} -x fasta {params.out}/lineage.ms {params.dir} {params.out} >>{log} 2>&1\n"
             "checkm qa -t {THREADS} -o 2 --tab_table -f {output.qa} {params.out}/lineage.ms {params.out} >>{log} 2>&1")

rule parse_checkm:
    input:   qa=rules.checkm.output.qa, tree_qa=rules.checkm.output.tree_qa
    output:  "stats/summary/checkm_{stage}.tsv"
    message: "Parse CheckM results for {wildcards.stage}"
    run:
        table = pandas.read_table(input.qa, dtype="str")
        tree_table = pandas.read_table(input.tree_qa, dtype="str", na_filter=False)
        all_table = pandas.merge(table, tree_table, on="Bin Id")
        res_table = all_table[["Bin Id", "Taxonomy (contained)", "Taxonomy (sister lineage)", "Genome size (Mbp)", "Completeness", "Contamination"]].copy()
        def extract_taxon(taxonomy):
            return str(taxonomy).split(";")[-1]
        for column in ["Taxonomy (contained)", "Taxonomy (sister lineage)"]:
            res_table[column] = res_table[column].apply(extract_taxon)
        res_table.to_csv(output[0], index=False, sep="\t")

rule combine_bins:
    input:   expand("{{stage}}/bins/{bin}.fasta", bin=BINS)
    output:  "{stage,(binning|propagation|reassembly)}/all.fasta"
    message: "Combine all contigs from {wildcards.stage}"
    shell:   "{SCRIPTS}/combine_contigs.py -r {input} > {output}"

rule reassembly_mock_binning:
    output:  "reassembly/binning.tsv"
    message: "Preparing reassembly mock binning"
    run:
        shell("rm -f {output}")
        for bin in BINS:
            shell("grep '>' reassembly/bins/{bin}.fasta | cut -c 2- | awk '{{print \"{bin}-\" $0 \"\\t{bin}\"}}' >> {output}")

#---- F1 stats -----------------------------------------------------------------
rule calc_f1:
    input:   "{stage}/binning.tsv", "{stage}/all.fasta"
    output:  "stats/summary/f1_{stage}.txt"
    message: "Calculating F1 metrics for {wildcards.stage}"
    shell:   "cd {stage}/bins/ && {SCRIPTS}/evaluate.py ../binning.tsv ../all.fasta fasta > ../../{output}"

#---- PCA ----------------------------------------------------------------------
# FRAGMENT_NAMES_BY_STAGE = {"reassembly": CAG_EDGES,
#                            "assembly": list(GROUPS.keys())}

def fragments_info_by_stage(wildcards):
    fragments=FRAGMENT_NAMES_BY_STAGE[wildcards.stage]
    return expand("stats/q_{stage}/runs_per_reference/{ref}/{fs}.info", stage=wildcards.stage, ref=wildcards.ref, fs=fragments)

rule pca:
    input:   "profile/{}/all.tsv".format(PROFILER),
             "binning/{}/unified_binning.tsv".format(BINNER),
             #"stats/q_{stage}/total.info"
    output:  "stats/summary/pca_{stage}.png"
    message: "Drawing PCA visualisation for {wildcards.stage}"
    shell:   "Rscript {SCRIPTS}/pca.R {input} {output}"

#---- TSNE ----------------------------------------------------------------------

rule tsne:
    input:   "profile/{}/all.tsv".format(PROFILER),
             "binning/{}/unified_binning.tsv".format(BINNER),
    output:  "stats/summary/tsne_{stage}.png"
    message: "Drawing BH-TSNE visualisation for {wildcards.stage}"
    shell:   "python2 {SCRIPTS}/run_tsne.py {input} {output}"
             " --percent 1.0 --iteration 2000 --perplexity 50"
