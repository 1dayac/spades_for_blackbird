configfile: "config.yaml"

import functools
import os
import os.path

from scripts.common import detect_reads, dump_dict

#Config parameters
IN = config["IN"]
SPADES = config["SPADES"]
SPADES_REASSEMBLY = config.get("SPADES_REASSEMBLY", SPADES)
BIN = config["BIN"]
SCRIPTS = config["SCRIPTS"]
SOFT = config["SOFT"]
K = int(config.get("K", 55))
SMALL_K = int(config.get("SMALL_K", 21))
MIN_CONTIG_LENGTH = int(config.get("MIN_CONTIG_LENGTH", 2000))
THREADS = config.get("THREADS", 16)

#Path to saves of necessary assembly stage
SAVES = "K{0}/saves/01_before_repeat_resolution/graph_pack".format(K)

#Flag files for stages completion
FINISHED_BINNING = "binning/all.log"
FINISHED_CHOOSING = "binning/choose_all.log"

#Autodetect samples and their reads
SAMPLE_DIRS = set(glob_wildcards(IN + "/{sample,sample\d+}")[0])
SAMPLE_COUNT = len(SAMPLE_DIRS)
SAMPLES = list()
for i in range(1, SAMPLE_COUNT + 1):
    sample_name = "sample" + str(i)
    if sample_name not in SAMPLE_DIRS:
        raise WorkflowError("Samples must be consecutive; missing " + sample_name)
    SAMPLES.append(sample_name)

SAMPLE_READS = dict(map(lambda sample: (sample, detect_reads(os.path.join(IN, sample))), SAMPLES))

def sample_reads(dir, wildcards):
    return SAMPLE_READS[wildcards.sample][dir]

left_reads  = functools.partial(sample_reads, 0)
right_reads = functools.partial(sample_reads, 1)

#Autodetect bins
CAGS, = glob_wildcards("binning/{cag,CAG\d+}")
CAGS.sort()
GOOD_CAGS, = glob_wildcards("binning/{cag,CAG\d+}/left.fastq")
GOOD_CAGS.sort()

onstart:
    try:
        os.mkdir("tmp")
    except:
        pass
    print("Detected", SAMPLE_COUNT, "samples in", IN)
    if GOOD_CAGS:
        print("Detected good (abundant) CAGs:", " ".join(GOOD_CAGS))

# ---- Main pipeline -----------------------------------------------------------

rule all:
    input:   FINISHED_BINNING
    message: "Dataset of {SAMPLE_COUNT} samples from {IN} has been processed."

rule assemble:
    input:   left = left_reads, right = right_reads
    output:  "assembly/{sample,sample\d+}.fasta"
    params:  "assembly/{sample}"
    log:     "assembly/{sample}.log"
    threads: THREADS
    message: "Assembling {wildcards.sample} with SPAdes"
    shell:   "{SPADES}/spades.py --meta -m 400 -t {threads} -1 {input.left} -2 {input.right}"
             " -o {params} >{log} 2>&1 && "
             "cp {params}/scaffolds.fasta {output}"

rule assemble_all:
    input:   expand("assembly/{sample}.fasta", sample=SAMPLES)
    message: "Assembled all samples"

rule descriptions:
    output:  expand("profile/{sample}.desc", sample=SAMPLES)
    message: "Generating sample descriptions"
    run:
        for sample in SAMPLES:
            with open("profile/{}.desc".format(sample), "w") as out:
                wildcards.sample = sample
                print(left_reads(wildcards),  file=out)
                print(right_reads(wildcards), file=out)

rule kmc:
    input:   "profile/{sample}.desc"
    output:  temp("tmp/{sample}.kmc_pre"), temp("tmp/{sample}.kmc_suf")
    params:  min_mult=2, tmp="tmp/{sample}_kmc", out="tmp/{sample}"
    log:     "profile/kmc_{sample}.log"
    threads: THREADS
    message: "Running kmc for {wildcards.sample}"
    shell:   "mkdir {params.tmp} && "
             "{SOFT}/kmc -k{SMALL_K} -t{threads} -ci{params.min_mult} -cs65535"
             " @{input} {params.out} {params.tmp} >{log} 2>&1 && "
             "rm -rf {params.tmp}"

rule multiplicities:
    input:   expand("tmp/{sample}.kmc_pre", sample=SAMPLES), expand("tmp/{sample}.kmc_suf", sample=SAMPLES)
    output:  "profile/kmers.mpl"
    params:  kmc_files=" ".join(expand("tmp/{sample}", sample=SAMPLES)), out="profile/kmers"
    log:     "profile/kmers.log"
    message: "Gathering {SMALL_K}-mer multiplicities from all samples"
    shell:   "{BIN}/kmer_multiplicity_counter -k {SMALL_K} -o {params.out} --sample 3"
             " -f {params.kmc_files} >{log} 2>&1 && "
             "rm tmp/*.sorted"

rule profile:
    input:   contigs="assembly/{sample}.fasta", mpl="profile/kmers.mpl"
    output:  "profile/{sample}.id", "profile/{sample}.mpl"
    log:     "profile/{sample}.log"
    message: "Counting contig abundancies for {wildcards.sample}"
    shell:   "{BIN}/contig_abundance_counter -k {SMALL_K} -w tmp -c {input.contigs}"
             " -n {SAMPLE_COUNT} -m profile/kmers -o profile/{wildcards.sample}"
             " -f assembly/{wildcards.sample}_splits.fasta"
             " -l {MIN_CONTIG_LENGTH} >{log} 2>&1"

rule canopy_pre:
    input:   expand("profile/{sample}.id", sample=SAMPLES)
    output:  "profile/canopy.in"
    message: "Preparing canopy input"
    shell:   "{SCRIPTS}/make_canopy_input.py {output} {input}"

rule canopy:
    input:   rules.canopy_pre.output
    output:  out="profile/canopy.out", prof="profile/canopy.prof"
    threads: THREADS
    message: "Running canopy clustering"
    shell:   "{SOFT}/cc.bin -n {threads} -i {input} -o {output.out} -c {output.prof} >profile/canopy.log 2>&1"

rule canopy_post:
    input:   rules.canopy.output.out
    output:  expand("annotation/{sample}.ann", sample=SAMPLES)
    message: "Preparing raw annotations"
    shell:   "{SCRIPTS}/parse_canopy_out.py {input} ./annotation"

rule binning:
    input:   contigs="assembly/{sample}.fasta", ann="annotation/{sample}.ann",
             left=left_reads, right=right_reads
    output:  "propagation/{sample}_edges.ann", "propagation/{sample}_edges.fasta"
    params:  saves="assembly/{sample}/" + SAVES, splits="assembly/{sample}_splits.fasta",
             out="propagation/{sample}_edges"
    log:     "binning/{sample}.log"
    message: "Propagating annotation & binning reads for {wildcards.sample}"
    shell:   "{BIN}/prop_binning -k {K} -s {params.saves} -c {input.contigs}"
             " -a {input.ann} -f {params.splits} -l {input.left} -r {input.right}"
             " -o binning -n {wildcards.sample} -d {params.out} >{log} 2>&1"

#Mock rule just for simplifying M-to-N dependencies in the stage graph
rule binning_all:
    input:   expand("propagation/{sample}_edges.ann", sample=SAMPLES)
    output:  touch(FINISHED_BINNING)
    message: "Binned all samples"

rule choose_samples:
    input:   flag=FINISHED_BINNING, prof=rules.canopy.output.prof
    #It's impossible to output "binning/{cag}/left.fastq", "binning/{cag}/right.fastq"
    #because the CAG can be filtered out
    output:  touch("binning/{cag,CAG\d+}.log")
    params:  cag="{cag}", dir="binning/{cag}"
    log:     "binning/choose_{cag}.log"
    message: "Choosing samples for {params.cag}"
    shell:   "{SCRIPTS}/choose_samples.py {params.cag} {input.prof} {params.dir} >{output} 2>&1"

#Launch this AFTER 'all'
rule choose_all:
    input:   expand("binning/{cag}.log", cag=CAGS)
    output:  touch(FINISHED_CHOOSING)
    message: "Filtered all CAGs"

rule generate_yaml:
    input:   FINISHED_CHOOSING
    output:  "reassembly/{cag}.yaml"
    message: "Generated config file for reassembly"
    run:
        with open(output[0], "w") as outfile:
            conf = {"k": SMALL_K, "sample_cnt": SAMPLE_COUNT,
                    "kmer_mult": str(rules.multiplicities.params.out),
                    "bin": wildcards.cag, "bin_prof": str(rules.canopy.output.prof)}
            dump_dict(conf, outfile)

rule reassemble:
    input:   left="binning/{cag}/left.fastq", right="binning/{cag}/right.fastq",
             config="reassembly/{cag}.yaml"
    output:  "reassembly/{cag}.fasta"
    params:  "reassembly/reassembly_{cag}"
    log:     "reassembly/reassembly_{cag}.log"
    threads: THREADS
    message: "Reassembling reads for {wildcards.cag}"
    shell:   "{SPADES_REASSEMBLY}/spades.py --meta -t {threads}"
             " --pe1-1 {input.left} --pe1-2 {input.right} --pe1-ff"
             " -o {params} --series-analysis {input.config} >{log} 2>&1 && "
             "cp {params}/scaffolds.fasta {output}"

#Launch this AFTER 'choose_all'
rule reassemble_all:
    input:   expand("reassembly/{cag}.fasta", cag=GOOD_CAGS)
    message: "Reassembled reads for all bins"
