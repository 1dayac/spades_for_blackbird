configfile: "config.yaml"

import os
import os.path

def gather_refs(data):
    if type(data) is list:
        for path in data:
            yield from gather_refs(path)
    else:
        if os.path.isdir(data):
            for path in os.listdir(data):
                if path.endswith(".fasta") or path.endswith(".fna"):
                     yield os.path.join(data, path)
        else:
            yield data

IN = config["IN"]
SPADES = config["SPADES"]
BIN = config["BIN"]
SCRIPTS = config["SCRIPTS"]
SOFT = config["SOFT"]
QUAST = config["QUAST"]
# TODO: there should be only one
METAQUAST = QUAST.replace("quast.py", "metaquast.py")
K = int(config.get("K", 55))
small_k = int(config.get("small_k", 21))
CONFIG = "K{0}/configs/config.info".format(K)
SAVES = "K{0}/saves/07_before_repeat_resolution/graph_pack".format(K)
MIN_CONTIG_LENGTH = int(config["MIN_CONTIG_LENGTH"])
CAG = config.get("CAG")
THREADS = config.get("THREADS", 16)

SAMPLES, = glob_wildcards(IN + "/{sample,sample\d+}")
SAMPLE_COUNT = len(SAMPLES)
CAGS, = glob_wildcards("binning/{cag,CAG\d+}")
GOOD_CAGS, = glob_wildcards("binning/{cag,CAG\d+}_1.fastq")
REFS = {os.path.splitext(os.path.basename(fullpath))[0]: fullpath for fullpath in gather_refs(config.get("REFS", []))}
def ref_path(wildcards):
    return REFS[wildcards.ref]
ALL_REFS = ",".join(path for path in REFS.values())

FINISHED_BINNING = expand("{sample}/binning.log", sample=SAMPLES)
STATS_DIR = "summary/stats"

# ---- Main pipeline -----------------------------------------------------------

rule all:
    input:   FINISHED_BINNING
    message: "Dataset of {SAMPLE_COUNT} samples from {IN} has been processed."

rule assemble:
    input:   left = IN + "/{sample}/left.fastq", right = IN + "/{sample}/right.fastq"
    output:  "assembly/{sample}.fasta"
    params:  "{sample}/assembly"
    log:     "{sample}/assembly.log"
    threads: THREADS
    message: "Assembling {wildcards.sample} with SPAdes"
    shell:
        "mkdir -p {wildcards.sample} && mkdir -p assembly && "
        "{SPADES}/spades.py --meta -t {threads} -1 {input.left} -2 {input.right} -o {params} >{log} 2>&1 && "
        "cp {params}/scaffolds.fasta {output}"

rule descriptions:
    output:  expand("{sample}.desc", sample=SAMPLES)
    message: "Generating sample descriptions"
    shell:   "{SCRIPTS}/dataset_desc_gen.sh {IN}/sample ./ >/dev/null"

rule kmc:
    input:   "{sample}.desc"
    output:  "tmp/{sample}.kmc_pre"
    params:  min_mult=2, tmp="tmp/{sample}_kmc", out="tmp/{sample}"
    log:     "sample/kmc.log"
    threads: THREADS
    message: "Running kmc for {wildcards.sample}"
    shell:
        "mkdir -p {params.tmp} && "
        "{SOFT}/kmc -k{small_k} -t{threads} -ci{params.min_mult} -cs65535 @{input} {params.out} {params.tmp} >{log} 2>&1 && "
        "rm -rf {params.tmp}"

rule multiplicities:
    input:   expand("tmp/{sample}.kmc_pre", sample=SAMPLES)
    output:  "kmers.mpl"
    params:  " ".join(expand("tmp/{sample}", sample=SAMPLES))
    log:     "multiplicities.log"
    message: "Gathering {small_k}-mer multiplicities from all samples"
    shell:
        "{BIN}/kmer_multiplicity_counter -k {small_k} -o kmers --sample 3 -f {params} >{log} 2>&1 && "
        "rm tmp/*.sorted"

rule profile:
    input:   contigs="assembly/{sample}.fasta", mpl="kmers.mpl"
    output:  "{sample}/{sample}.id"
    log:     "{sample}/profile.log"
    message: "Counting contig abundancies for {wildcards.sample}"
    shell:
        "{BIN}/contig_abundance_counter -k {small_k} -w tmp -c {input.contigs} -n {SAMPLE_COUNT} -m kmers -o {wildcards.sample}/{wildcards.sample} -l {MIN_CONTIG_LENGTH} >{log} 2>&1"

rule canopy_pre:
    input:   expand("{sample}/{sample}.id", sample=SAMPLES)
    output:  "canopy.in"
    message: "Preparing canopy input"
    shell:   "{SCRIPTS}/make_canopy_input.py {output} {input}"

rule canopy:
    input:   rules.canopy_pre.output
    output:  out = "canopy.out", prof = "canopy.prof"
    message: "Running canopy clustering"
    shell:   "{SCRIPTS}/canopy_launch.sh {input} {output.out} {output.prof}"

rule canopy_post:
    input:   rules.canopy.output.out
    output:  expand("{sample}.ann", sample=SAMPLES)
    message: "Preparing raw annotations"
    shell:   "{SCRIPTS}/parse_canopy_out.py {input} ./"

rule binning:
    input:
        contigs="assembly/{sample}.fasta", ann="{sample}.ann",
        left=IN + "/{sample}/left.fastq", right=IN + "/{sample}/right.fastq"
    output:  "{sample}/binning.log", "{sample}_edges.ann"
    params:  "{sample}"
    log:     "{sample}/binning.log"
    message: "Propagating annotation & binning reads for {wildcards.sample}"
    shell:
        "{BIN}/prop_binning -k {K} -s {wildcards.sample}/assembly/{SAVES} -c {input.contigs} -a {input.ann} -l {input.left} -r {input.right} -o binning -n {params} >{log} 2>&1"

rule choose_samples:
    input:   FINISHED_BINNING
    output:  "binning/{cag}.log"
    #output:  left="binning/{cag}_1.fastq", right="binning/{cag}_2.fastq"
    params:  "{cag}"
    log:     "binning/{cag}.log"
    message: "Choosing samples for {params}"
    shell:   "{SCRIPTS}/choose_samples.py {params} canopy.prof binning >{log} 2>&1"

#Launch this AFTER 'all'
rule choose_all:
    input:   expand("binning/{cag}.log", cag=CAGS)
    message: "Filtered all CAGs"

rule generate_yaml:
    output:  "reassembly/{cag}.yaml"
    message: "Generated config file for reassembly"
    run:
        with open(output[0], "w") as outfile:
            yaml = {"k": small_k, "sample_cnt": SAMPLE_COUNT, "kmer_mult": "kmers", "bin": wildcards.cag, "bin_prof": "canopy.prof"}
            #TODO: some sort of PyYAML
            for key, value in yaml.items():
                print(key, ": ", value, sep="", file=outfile)

rule reassemble:
    input:   left="binning/{cag}_1.fastq", right="binning/{cag}_2.fastq",
             config="reassembly/{cag}.yaml"
    output:  "reassembly/{cag}.fasta"
    params:  "reassembly/reassembly_{cag}"
    log:     "reassembly/reassembly_{cag}.log"
    threads: THREADS
    message: "Reassembling reads for {wildcards.cag}"
    shell:
        "mkdir -p reassembly && "
        "{SPADES}/spades.py --meta -t {threads} --pe1-1 {input.left} --pe1-2 {input.right} --pe1-ff -o {params} --series-analysis {input.config} >{log} 2>&1 && "
        "cp {params}/scaffolds.fasta {output}"

#Launch this AFTER 'choose_all'
rule reassemble_all:
    input:   expand("reassembly/{cag}.fasta", cag=GOOD_CAGS)
    message: "Reassembled reads for all bins"

#===============================================================================
#---- Statistics section -------------------------------------------------------
#===============================================================================

#---- Single alignments per sample per reference -------------------------------
rule quast_all_samples:
    input:   ref=ref_path, contigs=expand("assembly/{sample}.fasta", sample=SAMPLES)
    output:  "{STATS_DIR}/q_{ref}.tsv"
    params:  "summary/q_{ref}"
    log:     "summary/q_{ref}.log"
    message: "Aligning all samples on {wildcards.ref}"
    shell:   "{QUAST} -R {input.ref} {input.contigs} -o {params} >{log} 2>&1 && "
             "mkdir -p {STATS_DIR} && "
             "cp {params}/report.tsv {output}"

rule quast_all:
    input:   expand("{sample}/{ref}.cont", sample=SAMPLES, ref=REFS)
    message: "Calculated QUAST metrics"

#---- Contigs of interest ------------------------------------------------------
rule filter_all_samples:
    input:   "summary/q_{ref}/report.tsv"
    output:  expand("{sample}/{{ref}}.cont", sample=SAMPLES)
    message: "Filtering interesting contigs from all samples for {wildcards.ref}"
    params:  "summary/q_{ref}/"
    shell:   "{SCRIPTS}/filter_nucmer.py {params} {wildcards.ref}.cont 70"

#---- GF of combined sample ----------------------------------------------------
rule combine_filtered:
    input:   contigs=expand("assembly/{sample}.fasta", sample=SAMPLES), filters=expand("{sample}/{{ref}}.cont", sample=SAMPLES)
    output:  "summary/{ref}.fasta"
    message: "Gathering all interesting contigs for {wildcards.ref} into a single assembly"
    shell:   "{SCRIPTS}/filter_contigs.py {SAMPLE_COUNT} {output} {input.contigs} {input.filters}"

rule quast_combined:
    input:   ref=ref_path, contigs="summary/{ref}.fasta"
    output:  "summary/q_{ref}_all/report.tsv"
    params:  "summary/q_{ref}_all"
    log:     "summary/q_{ref}_all.log"
    threads: THREADS
    message: "Aligning combined sample on {wildcards.ref}"
    shell:   "{QUAST} -t {threads} -R {input.ref} {input.contigs} -o {params} >{log} 2>&1"

# Run this
rule quast_combined_all:
    input:   expand("summary/q_{ref}_all/report.tsv", ref=REFS)
    message: "Calculated QUAST metrics on all combined samples"


#---- Bins of interest ---------------------------------------------------------
rule int_bins:
    input:   "{sample}.ann", "{sample}/{ref}.cont"
    output:  "{sample}/{ref}.bin"
    message: "Filtering interesting bins for {wildcards.sample} aligned to {wildcards.ref}"
    shell:   "{SCRIPTS}/filter_bins.py {input} > {output}"

rule int_bins_all_samples:
    input:   expand("{sample}/{{ref}}.bin", sample=SAMPLES)
    output:  STATS_DIR + "/{ref}.bin"
    message: "Gathering interesting bins for {wildcards.ref} from all samples"
    run:
        bins = set()
        for in_fn in input:
            with open(in_fn) as infile:
                for line in infile:
                    bins.add(line)
        with open(output[0], "w") as outfile:
            for bin in bins:
                print(bin, file=outfile)

# Run this
rule int_bins_all:
    input:   expand("summary/{ref}.bin", ref=REFS)
    message: "Gathered all interesting bins"

#---- GF per bin per reference --------------------------------------
PROP = {"prelim": "", "prop": "_edges"}

#TODO: split into different directories per sample
rule split_bins:
    input:   lambda w: "assembly/{}{}.fasta".format(w.sample, PROP[w.prop]),
             lambda w: "{}{}.ann".format(w.sample, PROP[w.prop])
    output:  "{sample}/split_{prop}.log"
    params:  "binning/contigs_{prop}"
    message: "Splitting assembly of {wildcards.sample} between {wildcards.prop} bins"
    shell:
        "mkdir -p {params} && rm -f {params}/{wildcards.sample}-*.fasta && "
        "{SCRIPTS}/split_bins.py {input} {params} && "
        "touch {output}"

rule cat_binned_contigs:
    input:   expand("{sample}/split_{{prop}}.log", sample=SAMPLES)
    output:  "binning/contigs_{prop}/{cag,CAG\d+}.fasta"
    params:  "`ls binning/contigs_{prop}/*-{cag}.fasta`"
    message: "Combine binned contigs ({wildcards.prop}) for {wildcards.cag}"
    shell:   "cat {params} > {output}"

def stats_input(wildcards):
    if wildcards.stage == "reassembly":
        return expand("reassembly/{cag}.fasta", cag=CAGS)
    w_bin, w_prop = wildcards.stage.split("_", 2)
    if w_bin == "split":
        return expand("{sample}/split_{prop}.log", sample=SAMPLES, prop=w_prop)
    elif w_bin == "bin":
        return expand("binning/contigs_{prop}/{cag}.fasta", prop=w_prop, cag=CAGS)

def stats_data(wildcards):
    if wildcards.stage == "reassembly":
        return "`ls reassembly/CAG*.fasta`"
    w_bin, w_prop = wildcards.stage.split("_", 2)
    masks = {"bin": "CAG*", "split": "*-CAG*"}
    return "`ls binning/contigs_{}/{}.fasta`".format(w_prop, masks[w_bin])

rule quast_stats:
    input:   stats_input
    output:  "summary/q_{stage}.log"
    params:  data=stats_data, out="summary/q_{stage}", report=STATS_DIR + "/gf_{wildcards.stage}.tsv"
    log:     "summary/q_{stage}.log"
    threads: THREADS
    message: "Aligning {wildcards.stage} assemblies on all references"
    shell:   "{METAQUAST} -t {threads} -R {ALL_REFS} {params.data} -o {params.out} >{log} 2>&1 && "
             "mkdir -p {STATS_DIR} && "
             "cp '{params.out}/summary/TSV/Genome_fraction(%).tsv' {params.report}"

# Run this AFTER 'all'
rule stats_all:
    input:   expand("summary/q_{bin}_{prop}.log", bin=["split", "bin"], prop=PROP)
    message: "Gathered some numbers, deal with them."

rule stats_reassembly:
    input:   "summary/q_reassembly.log"
    message: "Gathered even more numbers, deal with them."

rule neat_table:
    input:   "summary/q_split_prelim.log"
    output:  "summary/table.tsv"
    params:  dir="summary/q_split_prelim", refs=" ".join(REFS)
    message: "Formatting a human-readable table from results"
    shell:   "{SCRIPTS}/format_table.py {output} {params.dir} {params.refs}"

#---- Propagator statistics ----------------------------------------------------
rule prop_stats:
    input:   prelim="{sample}.ann", prop="{sample}_edges.ann",
             contigs="assembly/{sample}.fasta", edges="assembly/{sample}_edges.fasta",
             ref=REFS.values() #, bins="{sample}/{ref}.bin"
    output:  "summary/prop_stats/{sample}.stats"
    message: "Calculating propagation statistics for {wildcards.sample}"
    shell:   "mkdir -p summary/prop_stats && "
             "{BIN}/stats -k {K} -s {wildcards.sample}/assembly/{SAVES} -r {input.ref} -c {input.contigs} -a {input.prelim} -e {input.edges} -p {input.prop} >{output}" #-b `cat {input.bins}`

# Run this
rule prop_stats_all:
    input:   expand("summary/prop_stats/{sample}.stats", sample=SAMPLES)
    message: "Calculated propagation statistics"

#---- PCA ----------------------------------------------------------------------
rule pca:
    input:   rules.canopy_pre.output, rules.canopy.output.out, "{sample}.cont"
    output:  "{sample}.png"
    message: "Doing some visualization"
    shell:
        "Rscript {SCRIPTS}/pca.R {input} {output}"

rule combine_contigs:
    input:   expand("{sample}/{ref}.cont", sample=SAMPLES, ref=REFS)
    output:  "summary/total.cont"
    message: "Combining interesting contigs for all samples/references"
    run:
        shell("rm -f {output}")
        for sample in SAMPLES:
            for ref in REFS:
                shell("awk '{{print $0 \"\t{ref}\"}}' {sample}/{ref}.cont >> {output}")

# Run this
rule pca_total:
    input:   rules.canopy_pre.output, rules.canopy.output.out, "summary/total.cont"
    output:  STATS_DIR + "/pca.png"
    shell:   "Rscript {SCRIPTS}/pca.R {input} {output}"
